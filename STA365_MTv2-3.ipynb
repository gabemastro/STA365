{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02e15d6",
   "metadata": {},
   "source": [
    "# STA365 Midterm Exam\n",
    "\n",
    "Name: Gabriel Mastromatteo $\\longleftarrow$ Double click and replace the underscore with your name to indicate your understanding and agreement to the following rules of the exam\n",
    "\n",
    "> ### Rules\n",
    "> 1. You may ask me questions privately on [piazza](https://piazza.com/class/m5jvyco84083fm) https://piazza.com/class/m5jvyco84083fm \n",
    ">    1. I will convert reasonable questions public posts and answer them publicly\n",
    ">    2. *With the exception of piazza Q&A...*\n",
    "> 2. The midterm exam is open notes and open internet (including chatbots) **but you may not collaborate with other humans to complete this exam, but you may use any resources available online**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352f9bb",
   "metadata": {},
   "source": [
    "## Part 1: Metropolis-Hastings\n",
    "\n",
    "**Metropolis-Hastings** targetting **stationary distribution** $p$ based on **proposal distribution** $q$ given below\n",
    "\n",
    "$$q(\\tilde x^{(t)} | x^{(t-1)}) = \\left(\\frac{2}{3}\\right)^{1-{\\tilde x^{(t)}}}\\left(\\frac{1}{3}\\right)^{\\tilde x^{(t)}} \\quad\n",
    "\\textrm{ and } \\quad p(x^{(t)}) = \\left(\\frac{1}{3}\\right)^{1-{x^{(t)}}}\\left(\\frac{2}{3}\\right)^{x^{(t)}}$$\n",
    "\n",
    "has **transition kernel** $K$ of transition probabilities \n",
    "\n",
    "$K = \\left[\\begin{array}{cc}\\Pr(x^{(t)}=0 \\rightarrow x^{(t+1)}=0) & \\Pr(x^{(t)}=1 \\rightarrow x^{(t+1)}=0)\\\\\\Pr(x^{(t)}=0 \\rightarrow x^{(t+1)}=1)& \\Pr(x^{(t)}=1 \\rightarrow x^{(t+1)}=1)\\end{array}\\right] = \\left[\\begin{array}{cl} 2/3 & 1/6 \\\\ 1/3 & 5/6 \\end{array}\\right]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1edfd",
   "metadata": {},
   "source": [
    "## Part 1A (5%)\n",
    "\n",
    "\n",
    "### How is this different from `Q3` in `Bayes_03_Metropolis_Hastings.ipynb`<br>and why is this?\n",
    "\n",
    "#### *Double Click and Answer below in this cell*\n",
    "\n",
    "<!-- The answer is not \"because it has been specified differently\": -->\n",
    "<!-- one is specified differently and the other changes as a result -->\n",
    "\n",
    "To start, because the proposal distributiion q is specififed diffrently it no longer \"cancels out\" in the accpetance porbability of the metropolis hastings algoritm. In HW3 since q was always going to be (1/2) no matter what x tilde was, \n",
    "$$\n",
    "\\frac{q(x^{(t-1)}|\\tilde x^{(t)})}{q(\\tilde x^{(t)}|x^{(t-1)})}\n",
    "$$ wouuld cancel out becuase the reuslt of q did not depend on x tilde. however now since the value will either be 2/3 or 1/3 this does not work. This in turn will adjust the accpetance probablity because it is now takign into acount he scaling factor hence, the final transition kernal has diffrent porbbalities than HW3. \n",
    "\n",
    "In this problem, the proposal distribution is asymmetricâ€”the probability of moving from one state to another depends on the current state. Because of this, the acceptance probability now must account for the imbalance in proposal probabilities, meaning that the transition kernel \n",
    "K\n",
    " changes as a result.\n",
    "The proposal was not just \"specified differently\"; rather, the asymmetry in \n",
    "q\n",
    " causes the acceptance probability to adjust, leading to different transition probabilities.\n",
    "\n",
    "### How is this similar to `Q3` in `Bayes_03_Metropolis_Hastings.ipynb`<br>and why is this true?\n",
    "\n",
    "#### *Double Click and Answer below in this cell*\n",
    "\n",
    "<!-- The answer is not \"because it has been specified the same way\": -->\n",
    "<!-- this is asking why the stationary distribution will be the same -->\n",
    "\n",
    "### **(b) How is this similar to Q3 in Bayes_03_Metropolis_Hastings.ipynb and why is this true?**\n",
    "\n",
    "To show why the stationary distribution remains the same in both cases, we need to verify that **detailed balance** holds for both transition kernels.\n",
    "\n",
    "### **Step 1: Detailed Balance Condition**\n",
    "For a Markov chain with transition matrix \\( K \\) and stationary distribution \\( p(x) \\), detailed balance requires:\n",
    "\n",
    "$$\n",
    "p(x) K(x \\to x') = p(x') K(x' \\to x)\n",
    "$$\n",
    "\n",
    "for all states \\( x, x' \\). This ensures that the probability flow between any two states is equal in both directions, leading to stationarity.\n",
    "\n",
    "### **Step 2: Verify for Q3 in HW3**\n",
    "From Q3, we have:\n",
    "\n",
    "- **Proposal distribution** (symmetric):\n",
    "\n",
    "  $$\n",
    "  q(\\tilde{x}^{(t)} | x^{(t-1)}) = \\frac{1}{2}, \\quad \\text{for all states}\n",
    "  $$\n",
    "\n",
    "- **Stationary distribution**:\n",
    "\n",
    "  $$\n",
    "  p(x^{(t)}) = \\left( \\frac{1}{3} \\right)^{1-x^{(t)}} \\left( \\frac{2}{3} \\right)^{x^{(t)}}\n",
    "  $$\n",
    "\n",
    "- **Transition probabilities**:\n",
    "\n",
    "  $$\n",
    "  K =\n",
    "  \\begin{bmatrix}\n",
    "  0.5 & 0.25 \\\\\n",
    "  0.5 & 0.75\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n",
    "Now, checking detailed balance for \\( x=0 \\) and \\( x'=1 \\):\n",
    "\n",
    "$$\n",
    "p(0) K(0 \\to 1) = p(1) K(1 \\to 0)\n",
    "$$\n",
    "\n",
    "Substituting values:\n",
    "\n",
    "$$\n",
    "\\left( \\frac{1}{3} \\right) (0.5) = \\left( \\frac{2}{3} \\right) (0.25)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{6} = \\frac{1}{6} \\quad \\text{(holds)}\n",
    "$$\n",
    "\n",
    "### **Step 3: Verify for This Problem (Asymmetric Proposal)**\n",
    "For this problem, the proposal distribution is asymmetric:\n",
    "\n",
    "$$\n",
    "q(\\tilde{x}^{(t)} | x^{(t-1)}) =\n",
    "\\begin{cases}\n",
    "    2/3, & \\text{if proposing to stay in the same state} \\\\\n",
    "    1/3, & \\text{if proposing to switch states}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Transition probabilities are:\n",
    "\n",
    "$$\n",
    "K =\n",
    "\\begin{bmatrix}\n",
    "2/3 & 1/6 \\\\\n",
    "1/3 & 5/6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Checking detailed balance for \\( x=0 \\) and \\( x'=1 \\):\n",
    "\n",
    "$$\n",
    "p(0) K(0 \\to 1) = p(1) K(1 \\to 0)\n",
    "$$\n",
    "\n",
    "Substituting values:\n",
    "\n",
    "$$\n",
    "\\left( \\frac{1}{3} \\right) (1/3) = \\left( \\frac{2}{3} \\right) (1/6)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{9} = \\frac{1}{9} \\quad \\text{(holds)}\n",
    "$$\n",
    "\n",
    "### **Step 4: Conclusion**\n",
    "Since **detailed balance holds in both cases**, the Markov chains defined by each transition matrix will converge to the **same stationary distribution** \\( p(x) \\). Even though the individual transition probabilities differ, Metropolis-Hastings **corrects for proposal asymmetry**, ensuring that the final distribution remains unchanged.\n",
    "\n",
    "Thus, the reason why the stationary distribution is the same in both cases is **not because the proposal distribution is the same**, but because the Metropolis-Hastings algorithm ensures detailed balance, which guarantees convergence to the target stationary distribution.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3112e2",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1B (5%)\n",
    "\n",
    "### What is the Metropolis-Hastings acceptance probability $\\alpha_{mh}$ here?\n",
    "\n",
    "#### *Double Click and Answer below in this cell*\n",
    "\n",
    "<!-- You don't have to write this in LaTeX but it's probably easy to do so -->\n",
    "$\\alpha_{mh} = $\n",
    "\n",
    "## Part 1B (5%)\n",
    "\n",
    "### **What is the Metropolis-Hastings acceptance probability \\( \\alpha_{mh} \\) here?**\n",
    "\n",
    "The Metropolis-Hastings acceptance probability is given by:\n",
    "\n",
    "$$\n",
    "\\alpha_{mh} = \\min \\left( 1, \\frac{p(\\tilde{x}) q(x^{(t-1)} | \\tilde{x})}{p(x^{(t-1)}) q(\\tilde{x} | x^{(t-1)})} \\right)\n",
    "$$\n",
    "\n",
    "Substituting the given values:\n",
    "\n",
    "$$\n",
    "\\alpha_{mh} = \\min \\left( 1, \\frac{\\left( \\frac{1}{3} \\right)^{1-\\tilde{x}} \\left( \\frac{2}{3} \\right)^{\\tilde{x}} \\cdot q(x^{(t-1)} | \\tilde{x})}{\\left( \\frac{1}{3} \\right)^{1-x^{(t-1)}} \\left( \\frac{2}{3} \\right)^{x^{(t-1)}} \\cdot q(\\tilde{x} | x^{(t-1)})} \\right)\n",
    "$$\n",
    "\n",
    "Since the proposal distribution \\( q \\) is asymmetric:\n",
    "\n",
    "$$\n",
    "q(\\tilde{x} | x^{(t-1)}) =\n",
    "\\begin{cases}\n",
    "    2/3, & \\text{if proposing to stay in the same state} \\\\\n",
    "    1/3, & \\text{if proposing to switch states}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "q(x^{(t-1)} | \\tilde{x}) =\n",
    "\\begin{cases}\n",
    "    2/3, & \\text{if staying in the same state} \\\\\n",
    "    1/3, & \\text{if switching states}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **What is the difference between the acceptance probability, proposal distribution, transition kernel, stationary distribution, and target distribution?**\n",
    "\n",
    "<!-- You don't have to use this answer structure template but it might help -->\n",
    "The proposal distribution... which is... and altogether this process results in the... and then finally the stationary distribution is... which are... \n",
    "\n",
    "- **The proposal distribution** is the probability of suggesting a new candidate state given the current state:\n",
    "\n",
    "  $$\n",
    "  q(\\tilde{x} | x^{(t-1)})\n",
    "  $$\n",
    "\n",
    "  Here, it is **asymmetric**, meaning that the likelihood of moving from one state to another is not equal in both directions.\n",
    "\n",
    "- **The acceptance probability** determines whether the proposed state is accepted or rejected:\n",
    "\n",
    "  $$\n",
    "  \\alpha_{mh} = \\min \\left( 1, \\frac{p(\\tilde{x}) q(x^{(t-1)} | \\tilde{x})}{p(x^{(t-1)}) q(\\tilde{x} | x^{(t-1)})} \\right)\n",
    "  $$\n",
    "\n",
    "  It corrects for imbalances in the proposal distribution to ensure that the Markov chain converges to the correct target distribution.\n",
    "\n",
    "- **The transition kernel** \\( K \\) represents the probability of moving between states after applying both the proposal distribution and the acceptance probability:\n",
    "\n",
    "  $$\n",
    "  K(x \\to x') = q(x' | x) \\alpha_{mh}(x, x')\n",
    "  $$\n",
    "\n",
    "  It defines the overall movement of the Markov chain.\n",
    "\n",
    "- **The target distribution** is the probability distribution we aim to sample from:\n",
    "\n",
    "  $$\n",
    "  p(x)\n",
    "  $$\n",
    "\n",
    "  In this case, it is **the desired distribution that we want our Markov Chain to converge to**.\n",
    "\n",
    "- **The stationary distribution** is the distribution that remains unchanged under the transition kernel:\n",
    "\n",
    "  $$\n",
    "  p(x) K(x \\to x') = p(x') K(x' \\to x)\n",
    "  $$\n",
    "\n",
    "  This means that if the Markov chain reaches this distribution, it will stay there over time. In this case, **the stationary distribution is equal to the target distribution**, confirming that the Metropolis-Hastings algorithm is correctly designed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6587c97",
   "metadata": {},
   "source": [
    "## Part 1C (5%)\n",
    "\n",
    "Let $\\alpha_{x^{(t-1)} \\rightarrow \\tilde x^{(t)} }$ be the Metropolis-Hastings acceptance probability for proposal $\\tilde x^{(t)}$ when at state $x^{(t-1)}$ and $\\alpha_{x^{(t-1)} \\rightarrow x^{(t)}}$ be the chance of moving to state $ x^{(t)}$ when at state $x^{(t-1)}$.\n",
    "\n",
    "> $$q(\\tilde x^{(t)} | x^{(t-1)}) = \\left(\\frac{2}{3}\\right)^{1-{\\tilde x^{(t)}}}\\left(\\frac{1}{3}\\right)^{\\tilde x^{(t)}} \\quad\n",
    "\\textrm{ and } \\quad p(x^{(t)}) = \\left(\\frac{1}{3}\\right)^{1-{x^{(t)}}}\\left(\\frac{2}{3}\\right)^{x^{(t)}}$$\n",
    "\n",
    "### Complete the following table\n",
    "\n",
    "The $\\alpha_{x^{(t-1)} \\rightarrow x^{(t)}}$ here may be given as calculated numbers or just $\\alpha_{x^{(t-1)} \\rightarrow \\tilde x^{(t)} }$ and $1-\\alpha_{x^{(t-1)} \\rightarrow \\tilde x^{(t)} }$. The rows with zero probability $x^{(t)}$ may be included in the table but are not required.\n",
    "\n",
    "| $$\\tilde x^{(t)}$$ | $$x^{(t-1)}$$ | $$p(\\tilde x^{(t)})$$ | $$p(x^{(t-1)})$$ | $$q(\\tilde x^{(t)} | x^{(t-1)})$$ | $$q(x^{(t-1)}|\\tilde x^{(t)})$$ | $$\\alpha_{x^{(t-1)} \\rightarrow x^{(t)} }$$ | $$x^{(t)}$$ |\n",
    "|-|-|-|-|-|-|-|-|\n",
    "| 0 | 0 | $$\\frac{1}{3}$$ | $$\\frac{1}{3}$$ | $$\\frac{2}{3}$$ | $$\\frac{2}{3}$$ | $$1$$ | 0 |\n",
    "| 0 | 1 | $$\\frac{1}{3}$$ | $$\\frac{2}{3}$$ | $$\\frac{2}{3}$$ | $$\\frac{1}{3}$$ | $$\\min \\left( 1, \\frac{\\frac{1}{3} \\times \\frac{1}{3}}{\\frac{2}{3} \\times \\frac{2}{3}} \\right) = \\min \\left( 1, \\frac{1}{4} \\right)$$ | 0 |\n",
    "| 1 | 0 | $$\\frac{2}{3}$$ | $$\\frac{1}{3}$$ | $$\\frac{1}{3}$$ | $$\\frac{2}{3}$$ | $$\\min \\left( 1, \\frac{\\frac{2}{3} \\times \\frac{2}{3}}{\\frac{1}{3} \\times \\frac{1}{3}} \\right) = \\min \\left( 1, 4 \\right)$$ | 1 |\n",
    "| 1 | 1 | $$\\frac{2}{3}$$ | $$\\frac{2}{3}$$ | $$\\frac{1}{3}$$ | $$\\frac{1}{3}$$ | $$1$$ | 1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34755f9d",
   "metadata": {},
   "source": [
    "## Part 1D (5%)\n",
    "\n",
    "Show that the **transition kernel** $K$ of transition probabilities defined by this **Metropolis Hastings** algorithm is\n",
    "\n",
    "$K = \\left[\\begin{array}{cc}\\Pr(x^{(t)}=0 \\rightarrow x^{(t+1)}=0) & \\Pr(x^{(t)}=1 \\rightarrow x^{(t+1)}=0)\\\\\\Pr(x^{(t)}=0 \\rightarrow x^{(t+1)}=1)& \\Pr(x^{(t)}=1 \\rightarrow x^{(t+1)}=1)\\end{array}\\right] = \\left[\\begin{array}{cl} 2/3 & 1/6 \\\\ 1/3 & 5/6 \\end{array}\\right]$\n",
    "\n",
    "### Use the probabilities from the table above\n",
    "\n",
    "#### *Double Click and Answer below in this cell*\n",
    "\n",
    "<!-- You don't have to write this in LaTeX but it's probably easy to do so -->\n",
    "$\\begin{align}\n",
    "\\Pr(s_0 \\rightarrow s_0) &={2/3 + (1/3)(1-1) = 2/3} \\\\\n",
    "\\Pr(s_0 \\rightarrow s_1) &={1(1/3) + (2/3)(1-1) = 1/3} \\\\\n",
    "\\Pr(s_1 \\rightarrow s_1) &={1(1/3) + (2/3)(1-(1/4)) = 5/6} \\\\\n",
    "\\Pr(s_1 \\rightarrow s_0) &={(1-1)(1/3) + (2/3)(1/4) = 1/6} \\\\\n",
    "\\end{align}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the following imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pymc\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2/3,1/6],[1/3, 5/6]])\n",
    "#A = np.array([[.5,.25],[.5, .75]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64694db",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A@A\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remainder of the midterm exam will be\n",
    "# based on the classic \"Old Faithful\" dataset\n",
    "\n",
    "old_faithful = pd.read_csv(\"https://gist.githubusercontent.com/curran/4b59d1046d9e66f2787780ad51a1cd87/raw/9ec906b78a98cf300947a37b56cfe70d01183200/data.tsv\", sep=\"\\t\")\n",
    "print(\"n\", old_faithful.shape, \"variables\")\n",
    "plt.plot(old_faithful.waiting, old_faithful.eruptions, '.')\n",
    "plt.xlabel(\"old_faithful.waiting (time to next eruption)\")\n",
    "plt.ylabel(\"old_faithful.eruptions (duration time period)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63726c01",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Recall the normal-gamma specification \n",
    "\n",
    "$$\\scriptsize\n",
    "\\begin{align*}\n",
    "p(\\theta,\\tau|x) &\\propto{} p(\\theta,\\tau,x) = p(x|\\theta)p(\\theta)p(\\tau) \\quad (\\theta \\perp\\!\\!\\perp \\tau) \\leftarrow \\text{independent priors} & p(\\theta|x,\\theta_0,\\tau_0, \\tau) &={} \\text{N}\\left(\\frac{\\left(\\tau_0 \\theta_0+\\tau\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau_0+n\\tau)}, \\sigma^{-2}=\\tau_0+n\\tau \\right)\\\\\n",
    "&={}  \\left[\\prod_{i=1}^n\\sqrt{\\frac{\\tau}{2\\pi}} e^{-\\frac{\\tau\\left(x_i-\\theta\\right)^2}{2}}\\right] \\sqrt{\\frac{\\tau_0}{2\\pi}} e^{-\\frac{\\tau_0\\left(\\theta-\\theta_0\\right)^2}{2}} \\frac{\\beta ^{\\alpha}}{\\Gamma(\\alpha)} \\tau^{\\frac{\\alpha}{2} -1}e^{-\\frac{\\beta}{2} \\tau} & p(\\tau|x, \\alpha, \\beta, \\theta) &={} \\text{Gamma}\\left(\\frac{\\alpha}{2}+\\frac{n}{2}, \\frac{1}{2}\\beta+\\frac{1}{2}\\sum_{i=1}^n\\left(x_i-\\theta\\right)^2 \\right)\n",
    "\\end{align*}$$\n",
    "\n",
    "### And consider the following specification for the Old Faithful data above\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\textrm{For $i$ in } 1,\\cdots, n &={} 272\\\\\n",
    "\\textrm{Let unobserved $u_i=1$ indicate the long time group} & \\quad \\textrm{so the data point belongs to upper right cluster of data}\\\\\n",
    "\\textrm{and unobserved $u_i=0$ indicate the short time group} & \\quad  \\textrm{so the data point belongs to bottom left cluster of data}\\\\\n",
    "u_i &\\sim{} \\textrm{Bernoulli}(p) \\\\\n",
    "p &\\sim{} \\textrm{beta}(\\alpha_0=1,\\beta_0=1)\\\\\n",
    "\\textrm{Let waiting duration} & \\\\\n",
    "w_i &\\sim{} N\\big(\\theta_{w0} + u_i \\times \\theta_{w1}, \\tau_w\\big) \\\\\n",
    "\\theta_{w0} &\\sim{} N\\big(\\mu_{w0}=55, \\tau_{w0}=1/5^2 \\big) & \\\\\n",
    "\\theta_{w1} &\\sim{} N\\big(\\mu_{w1}=30, \\tau_{w1}=1/5^2 \\big) & \\\\\n",
    "\\tau_w  &\\sim{} \\textrm{Gamma}\\left(\\alpha=\\frac{1}{2}, \\beta=\\frac{1}{2}10^2\\right)\\\\\n",
    "\\textrm{and eruption duration} & \\\\\n",
    "y_i &\\sim{} N\\big(\\theta_{y0} + u_i \\times \\theta_{y1}, \\tau_y\\big) & \\\\\n",
    "\\theta_{y0} &\\sim{} N\\big(\\mu_{y0}=2.0, \\tau_{y0}=1/0.5^2 \\big) & \\\\\n",
    "\\theta_{y1} &\\sim{} N\\big(\\mu_{y1}=2.5, \\tau_{y1}=1/0.5^2 \\big) & \\\\\n",
    "\\tau_y  &\\sim{} \\textrm{Gamma}\\left(\\alpha=\\frac{1}{2}, \\beta=\\frac{1}{2}1^2\\right)\\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b592f",
   "metadata": {},
   "source": [
    "## Part 2 (20%): Complete the specification above using PyMC\n",
    "- Use one beta distribution\n",
    "- Use one Bernoulli distribution with `shape=272`\n",
    "- Use four normal distributions for the location $\\theta$ parameters, each with `shape=1`\n",
    "- Use two gamma distributions for the precision $\\tau$ parameters, each with `shape=1`\n",
    "- Use two normal distributions for the two observation columns (as given below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If u is a vector (with `shape=272` in this case)\n",
    "# then `theta_w0 + u*theta_w1` creates a vector of length 272\n",
    "# which can be used for the mean of the observed `w` data along with `tau=tau_w`\n",
    "# so long as `shape=1` is used in the specification of `theta_w0` and `theta_w1`\n",
    "# which makes these random variables a \"vector\" as opposed to a \"scalar\"\n",
    "\n",
    "with pymc.Model() as OldFaithful:\n",
    "\n",
    "    # Prior for group assignment probability\n",
    "    p = pymc.Beta(\"p\", alpha=1, beta=1)\n",
    "    \n",
    "    # Group assignment indicator (binary latent variable)\n",
    "    u = pymc.Bernoulli(\"u\", p=p, shape=272)\n",
    "    \n",
    "    # Priors for waiting time parameters\n",
    "    theta_w0 = pymc.Normal(\"theta_w0\", mu=55, tau=1/5**2, shape=1)\n",
    "    theta_w1 = pymc.Normal(\"theta_w1\", mu=30, tau=1/5**2, shape=1)\n",
    "    tau_w = pymc.Gamma(\"tau_w\", alpha=0.5, beta=0.5 * 10**2, shape=1)\n",
    "    \n",
    "    # Priors for eruption duration parameters\n",
    "    theta_y0 = pymc.Normal(\"theta_y0\", mu=2.0, tau=1/0.5**2, shape=1)\n",
    "    theta_y1 = pymc.Normal(\"theta_y1\", mu=2.5, tau=1/0.5**2, shape=1)\n",
    "    tau_y = pymc.Gamma(\"tau_y\", alpha=0.5, beta=0.5 * 1**2, shape=1)\n",
    "    \n",
    "    # The observed data flows into the model through two entery points\n",
    "\n",
    "    obs_w = pymc.Normal(\"obs_w\", mu=theta_w0 + u * theta_w1, tau=tau_w, observed=old_faithful.waiting)\n",
    "    obs_y = pymc.Normal(\"obs_y\", mu=theta_y0 + u * theta_y1, tau=tau_y, observed=old_faithful.eruptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc.model_to_graphviz(OldFaithful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60458c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare the above to this cell to confirm the correctness of your setup \n",
    "pymc.model_to_graphviz(OldFaithful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with OldFaithful:\n",
    "    v1_fit = pymc.sample()\n",
    "\n",
    "# The error below is a result of no variation in some of the u_i\n",
    "# which indicates that we do not believe there is any uncertainty in these u_i\n",
    "\n",
    "# RuntimeWarning: invalid value encountered in scalar divide\n",
    "# (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v1_fit.posterior.u.shape)\n",
    "display(v1_fit.posterior.u.values.var(axis=1))\n",
    "display(v1_fit.posterior.u.values.mean(axis=1))\n",
    "plt.plot(sorted(v1_fit.posterior.u.values.mean(axis=1).mean(axis=0)))\n",
    "plt.title(\"sorted posterior averaged u_i\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc532dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(OldFaithful)\n",
    "OldFaithful.named_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152fc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare the above to this cell to confirm the correctness of your setup \n",
    "dir(OldFaithful)\n",
    "OldFaithful.named_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(v1_fit, var_names=['p', \n",
    "                                 'theta_w0', 'theta_w1', \n",
    "                                 'theta_y0', 'theta_y1', \n",
    "                                 'tau_w', 'tau_y'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare the above to this cell to confirm the correctness of your setup \n",
    "# Does not look at u since there are too many for the output to be meaningful\n",
    "az.plot_trace(v1_fit, var_names=['p', \n",
    "                                 'theta_w0', 'theta_w1', \n",
    "                                 'theta_y0', 'theta_y1', \n",
    "                                 'tau_w', 'tau_y'])\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(v1_fit, var_names=['p', \n",
    "                              'theta_w0', 'theta_w1', \n",
    "                              'theta_y0', 'theta_y1', \n",
    "                              'tau_w', 'tau_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8ffd3",
   "metadata": {},
   "source": [
    "## Part 3 (20%): Complete the specification above using PyMC again\n",
    "\n",
    "- Use one beta distribution\n",
    "- Use one Bernoulli distribution with `shape=272`\n",
    "- Now use two (not four) normal distributions for the location $\\theta$ parameters (as given below)\n",
    "    - based on using `mu=[55,30]` and `mu=[2,2.5]` (which will make each have `shape=2` by default), and `tau=1/25` and `tau=1/0.5**2`, respectively \n",
    "    - and converting to `theta_w_` and `theta_y_` as given below\n",
    "- Use one gamma distribution for the precision $\\tau$ parameters\n",
    "    - based on using `beta=[10**2/2, 1/2]` and `alpha=1/2` (which will make the distribution have `shape=2` by default)\n",
    "- Use two normal distributions for the two observation columns (as suggested below)\n",
    "    - based on using `theta_w_[u]` and `tau=tau[0]` and `theta_y_[u]` and `tau=tau[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For `u` a vector of 0's and 1's (with `shape=272` in this case)\n",
    "# if `theta_w_` has `shape=2` then `theta_w_[u]` creates a vector of length `u`\n",
    "# in the same manner as `(np.array([10,20])[stats.bernoulli(0.5).rvs(10)])`\n",
    "\n",
    "with pymc.Model() as OldFaithful2:\n",
    "    \n",
    "    # Prior for group assignment probability\n",
    "    p = pymc.Beta(\"p\", alpha=1, beta=1)\n",
    "    \n",
    "    # Group assignment indicator (binary latent variable)\n",
    "    u = pymc.Bernoulli(\"u\", p=p, shape=272)\n",
    "    \n",
    "    # Priors for waiting time parameters (combined into shape=2)\n",
    "    theta_w = pymc.Normal(\"theta_w\", mu=[55,30], tau=1/5**2)  # 3 points mu=[55,85] + 1 point tau=1/5**2\n",
    "    theta_w_ = pymc.Deterministic(\"theta_w_\", theta_w+pymc.math.stack([0,theta_w[0]])) \n",
    "    \n",
    "    # Priors for eruption duration parameters (combined into shape=2)\n",
    "    theta_y = pymc.Normal(\"theta_y\", mu=[2,2.5], tau=1/0.5**2)  # 3 points mu=[2,4.5] + 1 point tau=1/0.5**2\n",
    "    theta_y_ = pymc.Deterministic(\"theta_y_\", theta_y+pymc.math.stack([0,theta_y[0]]))\n",
    "    \n",
    "    # Prior for precision parameters (combined into shape=2)\n",
    "    tau = pymc.Gamma(\"tau\", alpha=0.5, beta=[10**2/2, 1/2], shape=2)\n",
    "    \n",
    "    # Observed data likelihood\n",
    "    obs_w = pymc.Normal(\"obs_w\", mu=theta_w_[u], tau=tau[0], observed=old_faithful.waiting)\n",
    "    obs_y = pymc.Normal(\"obs_y\", mu=theta_y_[u], tau=tau[1], observed=old_faithful.eruptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aada50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc.model_to_graphviz(OldFaithful2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9691dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare the above to this cell to confirm the correctness of your setup \n",
    "pymc.model_to_graphviz(OldFaithful2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ae481",
   "metadata": {},
   "outputs": [],
   "source": [
    "with OldFaithful2:\n",
    "    v2_fit = pymc.sample()\n",
    "\n",
    "# The error below is a result of no variation in some of the u_i\n",
    "# which indicates that we do not believe there is any uncertainty in these u_i\n",
    "\n",
    "# RuntimeWarning: invalid value encountered in scalar divide\n",
    "# (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9add51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(OldFaithful2)\n",
    "OldFaithful2.named_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare the above to this cell to confirm the correctness of your setup \n",
    "dir(OldFaithful2)\n",
    "OldFaithful2.named_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c33d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(v2_fit, var_names=['p', 'theta_w', 'theta_y', 'tau'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can compare the above to this cell to confirm the correctness of your setup \n",
    "az.plot_trace(v2_fit, var_names=['p', 'theta_w', 'theta_y', 'tau'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(v2_fit, var_names=['p', 'theta_w', 'theta_y', 'tau'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(v1_fit, var_names=['p', \n",
    "                              'theta_w0', 'theta_w1', \n",
    "                              'theta_y0', 'theta_y1', \n",
    "                              'tau_w', 'tau_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebbd99",
   "metadata": {},
   "source": [
    "\n",
    "## Part 4:<br>Complete the same specification using Python<br>as a Gibbs sampler with known full conditionals\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\textrm{For $i$ in } 1,\\cdots, n &={} 272\\\\\n",
    "\\textrm{Let unobserved $u_i=1$ indicate the long time group} & \\quad \\textrm{so the data point belongs to upper right cluster of data}\\\\\n",
    "\\textrm{and unobserved $u_i=0$ indicate the short time group} & \\quad  \\textrm{so the data point belongs to bottom left cluster of data}\\\\\n",
    "u_i &\\sim{} \\textrm{Bernoulli}(p) \\\\\n",
    "p &\\sim{} \\textrm{beta}(\\alpha_0=1,\\beta_0=1)\\\\\n",
    "\\textrm{Let waiting duration} & \\\\\n",
    "w_i &\\sim{} N\\big(\\theta_{w0} + u_i \\times \\theta_{w1}, \\tau_w\\big) \\\\\n",
    "\\theta_{w0} &\\sim{} N\\big(\\mu_{w0}=55, \\tau_{w0}=1/5^2 \\big) & \\\\\n",
    "\\theta_{w1} &\\sim{} N\\big(\\mu_{w1}=30, \\tau_{w1}=1/5^2 \\big) & \\\\\n",
    "\\tau_w  &\\sim{} \\textrm{Gamma}\\left(\\alpha=\\frac{1}{2}, \\beta=\\frac{1}{2}10^2\\right)\\\\\n",
    "\\textrm{and eruption duration} & \\\\\n",
    "y_i &\\sim{} N\\big(\\theta_{y0} + u_i \\times \\theta_{y1}, \\tau_y\\big) & \\\\\n",
    "\\theta_{y0} &\\sim{} N\\big(\\mu_{y0}=2.0, \\tau_{y0}=1/0.5^2 \\big) & \\\\\n",
    "\\theta_{y1} &\\sim{} N\\big(\\mu_{y1}=2.5, \\tau_{y1}=1/0.5^2 \\big) & \\\\\n",
    "\\tau_y  &\\sim{} \\textrm{Gamma}\\left(\\alpha=\\frac{1}{2}, \\beta=\\frac{1}{2}1^2\\right)\\\\\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588207e1",
   "metadata": {},
   "source": [
    "## Part 4A (10%): Getting $u$ and $p$ from the Joint\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\prod_{i=1}^n N(w_i|\\theta_{w0}+\\theta_{w1},\\tau_{w})^{u_i}N(w_i|\\theta_{w0},\\tau_{w})^{1-u_i} N(y_i|\\theta_{y0}+\\theta_{y1},\\tau_{y})^{u_i}N(w_i|\\theta_{y0},\\tau_{y})^{1-u_i} &\\longleftarrow{} \\textrm{likelihood}\\\\ \n",
    "\\times  \\prod_{i=1}^n p^{u_i} (1-p)^{1-u_i} \\times p(p)p(\\theta_{w0})p(\\theta_{w1})p(\\tau_{w})p(\\theta_{y0})p(\\theta_{y1})p(\\tau_{y}) &\\longleftarrow{} \\textrm{priors}\n",
    "\\end{align}$\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\Pr(u_i = 1 | - ) &\\propto{} N(w_i|\\theta_{w0}+\\theta_{w1},\\tau_{w}) N(y_i|\\theta_{y0}+\\theta_{y1},\\tau_{y})p\\\\\n",
    "\\Pr(u_i = 0 | - ) &\\propto{} N(w_i|\\theta_{w0},\\tau_{w}) N(y_i|\\theta_{y0},\\tau_{y})(1-p)\\\\\n",
    "\\Pr(u_i = u | - ) &={} \\frac{\\Pr(u_i = u | - )}{\\sum_j \\Pr(u_i = u_j | - )}\n",
    "\\end{align}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint\n",
    "stats.bernoulli(stats.beta(1,1).rvs(10)).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab016ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note\n",
    "# .rvs(size) gives an array while .rvs() gives a scalar\n",
    "# unless parameter is a vector (as demonstrated above)\n",
    "stats.beta(1,1).rvs(2), stats.beta(1,1).rvs(size=1), stats.beta(1,1).rvs() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcadfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 272\n",
    "G = 100\n",
    "\n",
    "thetas_w_tau0 = 1/5**2\n",
    "# Don't change these for Part4A: keep them set as given\n",
    "thetas_w_mu0 = np.array([54.533, 25.549])  # posterior means from a previous run\n",
    "thetas_w = np.zeros((2,G)) + thetas_w_mu0.reshape(2,1)\n",
    "\n",
    "thetas_y_tau0 = 1/0.5**2\n",
    "# Don't change these for Part4A: keep them set as given\n",
    "thetas_y_mu0 = np.array([2.043, 2.254])  # posterior means from a previous run\n",
    "thetas_y = np.zeros((2,G)) + thetas_y_mu0.reshape(2,1)\n",
    "\n",
    "taus_alpha = 1\n",
    "taus_beta = np.array([10**2, 1**2])  \n",
    "# Don't change these for Part4A: keep them set as given\n",
    "# posterior means from a previous run\n",
    "taus = np.zeros((2,G)) + np.array([0.028, 7.288]).reshape(2,1)\n",
    "\n",
    "us = np.zeros((n,G))\n",
    "ps = np.zeros(G)+0.5\n",
    "\n",
    "for g in range(1,G):\n",
    "    \n",
    "    # Compute probabilities for u_i = 1 and u_i = 0\n",
    "    prob_u1 = (stats.norm.pdf(old_faithful.waiting, loc=thetas_w[0, g-1] + thetas_w[1, g-1], scale=1/np.sqrt(taus[0, g-1])) *\n",
    "               stats.norm.pdf(old_faithful.eruptions, loc=thetas_y[0, g-1] + thetas_y[1, g-1], scale=1/np.sqrt(taus[1, g-1])) *\n",
    "               ps[g-1])\n",
    "    \n",
    "    prob_u0 = (stats.norm.pdf(old_faithful.waiting, loc=thetas_w[0, g-1], scale=1/np.sqrt(taus[0, g-1])) *\n",
    "               stats.norm.pdf(old_faithful.eruptions, loc=thetas_y[0, g-1], scale=1/np.sqrt(taus[1, g-1])) *\n",
    "               (1 - ps[g-1]))\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    prob_sum = prob_u1 + prob_u0\n",
    "    prob_u1 /= prob_sum  # Convert to conditional probability\n",
    "    \n",
    "    # Sample new values for u based on full conditional\n",
    "    us[:, g] = stats.bernoulli(prob_u1).rvs()\n",
    "    \n",
    "    # Sample new values for p using a standard beta update\n",
    "    ps[g] = stats.beta(1 + (us[:, g] == 1).sum(), 1 + (us[:, g] == 0).sum()).rvs()\n",
    "    \n",
    "    # Don't change these for Part4A: keep them set as given\n",
    "    thetas_w[:, g] = thetas_w[:, g-1]\n",
    "    thetas_y[:, g] = thetas_y[:, g-1]\n",
    "    taus[:, g] = taus[:, g-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35521332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: does this look right?\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(sorted(us[:,1:].mean(axis=1)))\n",
    "ax[1].hist(ps);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac5e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It should look about like this\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4))\n",
    "ax[0].plot(sorted(us[:,1:].mean(axis=1)))\n",
    "ax[1].hist(ps);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0afe5e9",
   "metadata": {},
   "source": [
    "## Part 4B (10%): Getting $\\theta_w$ and $\\theta_y$ from the Joint\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\prod_{i=1}^n N(w_i|\\theta_{w0}+\\theta_{w1},\\tau_{w})^{u_i}N(w_i|\\theta_{w0},\\tau_{w})^{1-u_i} N(y_i|\\theta_{y0}+\\theta_{y1},\\tau_{y})^{u_i}N(w_i|\\theta_{y0},\\tau_{y})^{1-u_i} &\\longleftarrow{} \\textrm{likelihood}\\\\ \n",
    "\\times  \\prod_{i=1}^n p^{u_i} (1-p)^{1-u_i} \\times p(p)p(\\theta_{w0})p(\\theta_{w1})p(\\tau_{w})p(\\theta_{y0})p(\\theta_{y1})p(\\tau_{y}) &\\longleftarrow{} \\textrm{priors}\n",
    "\\end{align}$\n",
    "\n",
    "\n",
    "$$\\scriptsize\n",
    "\\begin{align*}\n",
    "p(\\theta,\\tau|x) &\\propto{} p(\\theta,\\tau,x) = p(x|\\theta)p(\\theta)p(\\tau) \\quad (\\theta \\perp\\!\\!\\perp \\tau) \\leftarrow \\text{independent priors} & p(\\theta|x,\\theta_0,\\tau_0, \\tau) &={} \\text{N}\\left(\\frac{\\left(\\tau_0 \\theta_0+\\tau\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau_0+n\\tau)}, \\sigma^{-2}=\\tau_0+n\\tau \\right)\\\\\n",
    "&={}  \\left[\\prod_{i=1}^n\\sqrt{\\frac{\\tau}{2\\pi}} e^{-\\frac{\\tau\\left(x_i-\\theta\\right)^2}{2}}\\right] \\sqrt{\\frac{\\tau_0}{2\\pi}} e^{-\\frac{\\tau_0\\left(\\theta-\\theta_0\\right)^2}{2}} \\frac{\\beta ^{\\alpha}}{\\Gamma(\\alpha)} \\tau^{\\frac{\\alpha}{2} -1}e^{-\\frac{\\beta}{2} \\tau} & p(\\tau|x, \\alpha, \\beta, \\theta) &={} \\text{Gamma}\\left(\\frac{\\alpha}{2}+\\frac{n}{2}, \\frac{1}{2}\\beta+\\frac{1}{2}\\sum_{i=1}^n\\left(x_i-\\theta\\right)^2 \\right)\\\\{}\\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 272\n",
    "G = 100\n",
    "\n",
    "thetas_w_mu0 = np.array([55,30])\n",
    "thetas_w = np.zeros((2,G)) + thetas_w_mu0.reshape(2,1)\n",
    "thetas_w_tau0 = 1/5**2\n",
    "\n",
    "thetas_y_mu0 = np.array([2.0,2.5])\n",
    "thetas_y = np.zeros((2,G)) + thetas_y_mu0.reshape(2,1)\n",
    "thetas_y_tau0 = 1/0.5**2\n",
    "\n",
    "taus_alpha = 1\n",
    "taus_beta = np.array([10**2, 1**2])  \n",
    "# Don't change these for Part4A: keep them set as given\n",
    "# posterior means from a previous run\n",
    "taus = np.zeros((2,G)) + np.array([0.028, 7.515]).reshape(2,1)\n",
    "\n",
    "us = np.zeros((n,G))\n",
    "ps = np.zeros(G)+0.5\n",
    "\n",
    "for g in range(1,G):\n",
    "    \n",
    "    # Sample latent variable `us`\n",
    "    us[:, g] = stats.bernoulli(ps[g-1]).rvs(n)\n",
    "    ps[g] = stats.beta(1, 1).rvs()\n",
    "    \n",
    "    # Get the indices for each group\n",
    "    idx_u1 = us[:, g] == 1  # Group where u_i = 1\n",
    "    idx_u0 = us[:, g] == 0  # Group where u_i = 0\n",
    "    \n",
    "    # Update theta_w[0] (baseline mean waiting time)\n",
    "    prec = thetas_w_tau0 + taus[0, g-1] * np.sum(idx_u0)  # Only for u=0\n",
    "    tmp = thetas_w_tau0 * thetas_w_mu0[0] + taus[0, g-1] * np.sum(old_faithful[\"waiting\"][idx_u0])\n",
    "    mu = tmp / prec\n",
    "    thetas_w[0, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "    \n",
    "    # Update theta_w[1] (incremental waiting time for u=1 group)\n",
    "    prec = thetas_w_tau0 + taus[0, g-1] * np.sum(idx_u1)  # Only for u=1\n",
    "    tmp = thetas_w_tau0 * thetas_w_mu0[1] + taus[0, g-1] * np.sum(old_faithful[\"waiting\"][idx_u1] - thetas_w[0, g])\n",
    "    mu = tmp / prec\n",
    "    thetas_w[1, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "    \n",
    "    # Update theta_y[0] (baseline mean eruption time)\n",
    "    prec = thetas_y_tau0 + taus[1, g-1] * np.sum(idx_u0)  # Only for u=0\n",
    "    tmp = thetas_y_tau0 * thetas_y_mu0[0] + taus[1, g-1] * np.sum(old_faithful[\"eruptions\"][idx_u0])\n",
    "    mu = tmp / prec\n",
    "    thetas_y[0, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "    \n",
    "    # Update theta_y[1] (incremental eruption time for u=1 group)\n",
    "    prec = thetas_y_tau0 + taus[1, g-1] * np.sum(idx_u1)  # Only for u=1\n",
    "    tmp = thetas_y_tau0 * thetas_y_mu0[1] + taus[1, g-1] * np.sum(old_faithful[\"eruptions\"][idx_u1] - thetas_y[0, g])\n",
    "    mu = tmp / prec\n",
    "    thetas_y[1, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "    \n",
    "    # Don't change these for Part4B: keep them set as given\n",
    "    taus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: does this look right?\n",
    "thetas_w[:,1:].mean(axis=1), old_faithful.waiting.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: does this look right?\n",
    "thetas_y[:,1:].mean(axis=1), old_faithful.eruptions.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202190c",
   "metadata": {},
   "source": [
    "## Part 4C (10%): Getting $\\tau$ from the Joint\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\prod_{i=1}^n N(w_i|\\theta_{w1},\\tau_{w})^{u_i}N(w_i|\\theta_{w0},\\tau_{w})^{1-u_i} N(y_i|\\theta_{y1},\\tau_{y})^{u_i}N(w_i|\\theta_{y0},\\tau_{y})^{1-u_i} &\\longleftarrow{} \\textrm{likelihood}\\\\ \n",
    "\\times  \\prod_{i=1}^n p^{u_i} (1-p)^{1-u_i} \\times p(p)p(\\theta_{w0})p(\\theta_{w1})p(\\tau_{w})p(\\theta_{y0})p(\\theta_{y1})p(\\tau_{y}) &\\longleftarrow{} \\textrm{priors}\n",
    "\\end{align}$\n",
    "\n",
    "\n",
    "$$\\scriptsize\n",
    "\\begin{align*}\n",
    "p(\\theta,\\tau|x) &\\propto{} p(\\theta,\\tau,x) = p(x|\\theta)p(\\theta)p(\\tau) \\quad (\\theta \\perp\\!\\!\\perp \\tau) \\leftarrow \\text{independent priors} & p(\\theta|x,\\theta_0,\\tau_0, \\tau) &={} \\text{N}\\left(\\frac{\\left(\\tau_0 \\theta_0+\\tau\\sum_{i=1}^{n}x_{i}\\right)}{(\\tau_0+n\\tau)}, \\sigma^{-2}=\\tau_0+n\\tau \\right)\\\\\n",
    "&={}  \\left[\\prod_{i=1}^n\\sqrt{\\frac{\\tau}{2\\pi}} e^{-\\frac{\\tau\\left(x_i-\\theta\\right)^2}{2}}\\right] \\sqrt{\\frac{\\tau_0}{2\\pi}} e^{-\\frac{\\tau_0\\left(\\theta-\\theta_0\\right)^2}{2}} \\frac{\\beta ^{\\alpha}}{\\Gamma(\\alpha)} \\tau^{\\frac{\\alpha}{2} -1}e^{-\\frac{\\beta}{2} \\tau} & p(\\tau|x, \\alpha, \\beta, \\theta) &={} \\text{Gamma}\\left(\\frac{\\alpha}{2}+\\frac{n}{2}, \\frac{1}{2}\\beta+\\frac{1}{2}\\sum_{i=1}^n\\left(x_i-\\theta\\right)^2 \\right)\\\\{}\\\\\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 272\n",
    "G = 100\n",
    "\n",
    "thetas_w_tau0 = 1/5**2\n",
    "# Don't change these for Part4C: keep them set as given\n",
    "thetas_w_mu0 = np.array([54.533, 25.549])  # posterior means from a previous run\n",
    "thetas_w = np.zeros((2,G)) + thetas_w_mu0.reshape(2,1)\n",
    "\n",
    "thetas_y_tau0 = 1/0.5**2\n",
    "# Don't change these for Part4C: keep them set as given\n",
    "thetas_y_mu0 = np.array([2.043, 2.254])  # posterior means from a previous run\n",
    "thetas_y = np.zeros((2,G)) + thetas_y_mu0.reshape(2,1)\n",
    "\n",
    "taus_alpha = 1\n",
    "taus_beta = np.array([10**2, 1**2])\n",
    "taus = np.zeros((2,G)) + taus_alpha/taus_beta.reshape(2,1)\n",
    "\n",
    "us = np.zeros((n,G))\n",
    "ps = np.zeros(G)+0.5\n",
    "\n",
    "for g in range(1,G):\n",
    "    \n",
    "    # For Part4C...\n",
    "    # Feel free to change this in any manner you wish\n",
    "    # to help confirm that your tau update is working \n",
    "    us[:, g] = stats.bernoulli(0.5).rvs(n)\n",
    "    \n",
    "    # For Part4C...\n",
    "    # Feel free to change this in any manner you wish\n",
    "    # to help confirm that your tau update is working \n",
    "    ps[g] = stats.beta(1, 1).rvs()\n",
    "\n",
    "    # Don't change these for now, just keep them fixed on the given\n",
    "    # posterior means from a previous run \n",
    "    thetas_w\n",
    "    thetas_y\n",
    "    \n",
    "    # Fix taus[0,g] (Waiting Time Precision)\n",
    "    sum_squares_w0 = np.sum((old_faithful.waiting[us[:, g] == 0] - thetas_w[0, g])**2)\n",
    "    sum_squares_w1 = np.sum((old_faithful.waiting[us[:, g] == 1] - thetas_w[1, g])**2)\n",
    "\n",
    "    taus[0, g] = stats.gamma(\n",
    "        a=taus_alpha + n / 2, \n",
    "        scale=1 / (taus_beta[0] / 2 + (sum_squares_w0 + sum_squares_w1) / 2)  # Fixed inverse\n",
    "    ).rvs()\n",
    "\n",
    "    # Fix taus[1,g] (Eruption Duration Precision)\n",
    "    sum_squares_y0 = np.sum((old_faithful.eruptions[us[:, g] == 0] - thetas_y[0, g])**2)\n",
    "    sum_squares_y1 = np.sum((old_faithful.eruptions[us[:, g] == 1] - thetas_y[1, g])**2)\n",
    "\n",
    "    taus[1, g] = stats.gamma(\n",
    "        a=taus_alpha + n / 2, \n",
    "        scale=1 / (taus_beta[1] / 2 + (sum_squares_y0 + sum_squares_y1) / 2)  # Fixed inverse\n",
    "    ).rvs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: does this look right?\n",
    "taus[:,1:].mean(axis=1), 1/old_faithful.waiting.var(), 1/old_faithful.eruptions.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could fix u's or put in u imputation to check the precision on the two groups\n",
    "# the differences below are due to the priors being set for the two groups\n",
    "# as opposed to for \"all the data together\" of the \"random u\" model \n",
    "# but numbers like these are sufficiently confirmatory\n",
    "taus[:,1:].mean(axis=1), 1/old_faithful.waiting.var(), 1/old_faithful.eruptions.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a92a265",
   "metadata": {},
   "source": [
    "## Part 4D (10%): Complete Gibbs Sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 272\n",
    "G = 100\n",
    "\n",
    "thetas_w_mu0 = np.array([55,30])\n",
    "thetas_w = np.zeros((2,G)) + thetas_w_mu0.reshape(2,1)\n",
    "thetas_w_tau0 = 1/5**2\n",
    "\n",
    "thetas_y_mu0 = np.array([2.0,2.5])\n",
    "thetas_y = np.zeros((2,G)) + thetas_y_mu0.reshape(2,1)\n",
    "thetas_y_tau0 = 1/0.5**2\n",
    "\n",
    "taus_alpha = 1\n",
    "taus_beta = np.array([10**2, 1**2])\n",
    "taus = np.zeros((2,G)) + taus_alpha/taus_beta.reshape(2,1)\n",
    "\n",
    "us = np.zeros((n,G))\n",
    "ps = np.zeros(G)+0.5\n",
    "\n",
    "for g in range(1,G):\n",
    "    \n",
    "    # **Step 1: Update u (latent cluster assignment)**\n",
    "    prob_u1 = (stats.norm.pdf(old_faithful[\"waiting\"], loc=thetas_w[0, g-1] + thetas_w[1, g-1], scale=1/np.sqrt(taus[0, g-1])) *\n",
    "               stats.norm.pdf(old_faithful[\"eruptions\"], loc=thetas_y[0, g-1] + thetas_y[1, g-1], scale=1/np.sqrt(taus[1, g-1])) *\n",
    "               ps[g-1])\n",
    "    \n",
    "    prob_u0 = (stats.norm.pdf(old_faithful[\"waiting\"], loc=thetas_w[0, g-1], scale=1/np.sqrt(taus[0, g-1])) *\n",
    "               stats.norm.pdf(old_faithful[\"eruptions\"], loc=thetas_y[0, g-1], scale=1/np.sqrt(taus[1, g-1])) *\n",
    "               (1 - ps[g-1]))\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    prob_sum = prob_u1 + prob_u0\n",
    "    prob_u1 /= prob_sum  # Convert to conditional probability\n",
    "    us[:, g] = stats.bernoulli(prob_u1).rvs()\n",
    "\n",
    "    # **Step 2: Update p (mixing proportion)**\n",
    "    ps[g] = stats.beta(1 + np.sum(us[:, g]), 1 + n - np.sum(us[:, g])).rvs()\n",
    "    \n",
    "    # Group indices\n",
    "    idx_u1 = us[:, g].astype(bool)  # Boolean mask for u=1\n",
    "    idx_u0 = ~idx_u1  # Boolean mask for u=0\n",
    "    \n",
    "    # **Step 3: Update theta_w[0] (Short waiting time mean)**\n",
    "    prec = thetas_w_tau0 + taus[0, g-1] * np.sum(idx_u0)\n",
    "    tmp = thetas_w_tau0 * thetas_w_mu0[0] + taus[0, g-1] * np.sum(old_faithful[\"waiting\"][idx_u0])\n",
    "    mu = tmp / prec\n",
    "    thetas_w[0, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "    \n",
    "    # **Step 4: Update theta_w[1] (Long waiting time mean)**\n",
    "    num_u1 = np.sum(idx_u1)\n",
    "    if num_u1 > 0:\n",
    "        prec = thetas_w_tau0 + taus[0, g-1] * num_u1\n",
    "        tmp = thetas_w_tau0 * thetas_w_mu0[1] + taus[0, g-1] * np.sum(old_faithful[\"waiting\"][idx_u1] - thetas_w[0, g])\n",
    "    else:\n",
    "        prec = thetas_w_tau0\n",
    "        tmp = thetas_w_tau0 * thetas_w_mu0[1]\n",
    "    \n",
    "    mu = tmp / prec\n",
    "    thetas_w[1, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "\n",
    "    # **Step 5: Update theta_y[0] (Short eruption duration mean)**\n",
    "    prec = thetas_y_tau0 + taus[1, g-1] * np.sum(idx_u0)\n",
    "    tmp = thetas_y_tau0 * thetas_y_mu0[0] + taus[1, g-1] * np.sum(old_faithful[\"eruptions\"][idx_u0])\n",
    "    mu = tmp / prec\n",
    "    thetas_y[0, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "    \n",
    "    # **Step 6: Update theta_y[1] (Long eruption duration mean)**\n",
    "    if num_u1 > 0:\n",
    "        prec = thetas_y_tau0 + taus[1, g-1] * num_u1\n",
    "        tmp = thetas_y_tau0 * thetas_y_mu0[1] + taus[1, g-1] * np.sum(old_faithful[\"eruptions\"][idx_u1] - thetas_y[0, g])\n",
    "    else:\n",
    "        prec = thetas_y_tau0\n",
    "        tmp = thetas_y_tau0 * thetas_y_mu0[1]\n",
    "    \n",
    "    mu = tmp / prec\n",
    "    thetas_y[1, g] = stats.norm(loc=mu, scale=1/np.sqrt(prec)).rvs()\n",
    "    \n",
    "    # **Step 7: Update tau_w (precision for waiting times)**\n",
    "    sum_squares_w0 = np.sum((old_faithful[\"waiting\"][idx_u0] - thetas_w[0, g])**2)\n",
    "    sum_squares_w1 = np.sum((old_faithful[\"waiting\"][idx_u1] - (thetas_w[0, g] + thetas_w[1, g]))**2)\n",
    "\n",
    "    taus[0, g] = stats.gamma(\n",
    "        a=taus_alpha + n / 2, \n",
    "        scale=1 / (taus_beta[0] / 2 + (sum_squares_w0 + sum_squares_w1) / 2)\n",
    "    ).rvs()\n",
    "\n",
    "    # **Step 8: Update tau_y (precision for eruption durations)**\n",
    "    sum_squares_y0 = np.sum((old_faithful[\"eruptions\"][idx_u0] - thetas_y[0, g])**2)\n",
    "    sum_squares_y1 = np.sum((old_faithful[\"eruptions\"][idx_u1] - (thetas_y[0, g] + thetas_y[1, g]))**2)\n",
    "\n",
    "    taus[1, g] = stats.gamma(\n",
    "        a=taus_alpha + n / 2, \n",
    "        scale=1 / (taus_beta[1] / 2 + (sum_squares_y0 + sum_squares_y1) / 2)\n",
    "    ).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e12a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7be9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taus.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_w.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_y.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(v1_fit, var_names=['p', \n",
    "                              'theta_w0', 'theta_w1', \n",
    "                              'theta_y0', 'theta_y1', \n",
    "                              'tau_w', 'tau_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9811d",
   "metadata": {},
   "source": [
    "<!-- ## Part 1:<br>Complete the specification below (A) using PyMC<br>and (B) as a Gibbs sampler with known full conditionals using Python -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
